{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structured QA \n",
    "In this notebook we present a task of structured QA over an [NBA games dataset](https://www.kaggle.com/datasets/nathanlauga/nba-games). \\\n",
    "Our objectives is to create a chain that translates our question into a PostgreSQL query, execute it and reply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install langchain langchain-experimental sqlalchemy python-dotenv openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import dotenv\n",
    "from langchain.utilities import SQLDatabase\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import create_sql_query_chain\n",
    "from langchain.schema.runnable import RunnableParallel\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "# from langchain.agents import AgentExecutor\n",
    "from langchain_experimental.sql import SQLDatabaseChain\n",
    "from langchain.schema.output_parser import NoOpOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not dotenv.load_dotenv():\n",
    "    os.environ[\"DB_CONNECT\"] = \"db-uri\"\n",
    "    os.environ[\"OPENAI_API_KEY\"] = \"openai-api-key\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What the LLM needs\n",
    "To enable the LLM to query our data we need to provide it with information about it and the environment. \\\n",
    "We need to define the following:\n",
    "  * DB Dialect -> Postgres\n",
    "  * DB structure -> Dinamically from the db\n",
    "\n",
    "Both the dialect and the structure are passed to the LLM through the PROMPT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"\"\"You are a PostgreSQL expert. Given an input question, first create a syntactically correct PostgreSQL query to run, then look at the results of the query and return the answer to the input question.\n",
    "Unless the user specifies in the question a specific number of examples to obtain, query for at most {top_k} results using the LIMIT clause as per PostgreSQL. You can order the results to return the most informative data in the database.\n",
    "Never query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap each column name in double quotes (\") to denote them as delimited identifiers.\n",
    "Pay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\n",
    "Pay attention to use CURRENT_DATE function to get the current date, if the question involves \"today\".\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: Question here\n",
    "SQLQuery: SQL Query to run\n",
    "SQLResult: Result of the SQLQuery\n",
    "Answer: Final answer here\n",
    "\n",
    "Only use the following tables:\n",
    "{table_info}\n",
    "\n",
    "Question: {input}\n",
    "\"\"\"\n",
    "postgres_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\", \"table_info\", \"top_k\"],\n",
    "    template=PROMPT,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the database and LLM object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = SQLDatabase.from_uri(os.getenv(\"DB_CONNECT\"))\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo-16k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _strip(text: str) -> str:\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "inputs = {\n",
    "    \"input\": lambda x: x[\"question\"] + \"\\nSQLQuery: \",\n",
    "    \"top_k\": lambda _: 10,\n",
    "    \"table_info\": lambda x: db.get_table_info(table_names=x.get(\"table_names_to_use\")),\n",
    "}\n",
    "\n",
    "# Langchain Expression Language\n",
    "sql_query_chain = (\n",
    "    RunnableParallel(inputs)\n",
    "    | postgres_prompt\n",
    "    | llm.bind(stop=[\"\\nSQLResult:\"])\n",
    "    | NoOpOutputParser()\n",
    "    | _strip\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query_chain.invoke(\n",
    "    {\n",
    "        \"question\": \"What game did Luka Doncic have the highest three pointers percentage?\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in sql_query_chain.stream(\n",
    "    {\n",
    "        \"question\": \"What game did Luka Doncic have the highest three pointers percentage?\"\n",
    "    }\n",
    "):\n",
    "    print(s, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In reality LangChain already handles all the necessary abstractions, like shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_chain = SQLDatabaseChain.from_llm(llm, db, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_chain.run(\"What game did Luka Doncic have the highest three pointers percentage in?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_chain.run(\"What game has an ID of 22101059?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_chain.run(\"Which teams have ID's of 1610612766 and 1610612742?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fun but not really usefull. Lets try and make it return more human readable data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"\"\"You are a PostgreSQL expert. Given an input question, first create a syntactically correct PostgreSQL query to run, then look at the results of the query and return the answer to the input question.\n",
    "Unless the user specifies in the question a specific number of examples to obtain, query for at most {top_k} results using the LIMIT clause as per PostgreSQL. You can order the results to return the most informative data in the database.\n",
    "Never query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap each column name in double quotes (\") to denote them as delimited identifiers.\n",
    "Pay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\n",
    "Pay attention to use CURRENT_DATE function to get the current date, if the question involves \"today\".\n",
    "Do not return ID's of teams and players, instead return their names.\n",
    "When talking about a game always mention between which teams the game was played, never just respond with its ID.\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: Question here\n",
    "SQLQuery: SQL Query to run\n",
    "SQLResult: Result of the SQLQuery\n",
    "Answer: Final answer here\n",
    "\n",
    "Only use the following tables:\n",
    "{table_info}\n",
    "\n",
    "Question: {input}\n",
    "\"\"\"\n",
    "postgres_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\", \"table_info\", \"top_k\"],\n",
    "    template=PROMPT,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_chain = SQLDatabaseChain.from_llm(llm, db, prompt=postgres_prompt, verbose=True)\n",
    "# , use_query_checker=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_chain.run(\"What game did Luka Doncic have the highest three pointers percentage in?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_chain.run(\n",
    "    \"What game did Luka Doncic have the highest three pointers percentage in and what was it?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible improvements to the existing flow:\n",
    "* Better database table and column descriptions\n",
    "* Few-shot examples in the prompt (static or dynamic)\n",
    "\n",
    "What is missing:\n",
    "* Any type ability to hold a conversation.\n",
    "* Ability to recover from its own mistakes.\n",
    "* Support for multiple SQL queries."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
